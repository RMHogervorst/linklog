---
# title for above
title: "Twimlai Engineering Production Nlp T Mobile"
date: 2022-11-23T07:49:33+01:00
draft: false
rating: 4
identifyer:
  - url: https://twimlai.com/podcast/twimlai/engineering-production-nlp-systems-at-t-mobile-with-heather-nolis/
RSS: 
  - url: "https://chrt.fm/track/4D4ED/traffic.megaphone.fm/MLN6930154670.mp3?updated=1669060374"
  - length: 0
  - duration: 2633
  - image: "https://megaphone.imgix.net/podcasts/6383f07c-69d5-11ed-9284-63321b2b4185/image/f47323.jpg?ixlib=rails-2.1.2&max-w=3000&max-h=3000&fit=crop&auto=format,compress"
  - title: "Engineering Production NLP Systems at T-Mobile with Heather Nolis - #600"
  - link: "https://twimlai.com/go/600"
# full title of resource
link_title: "Engineering Production NLP Systems at T-Mobile with Heather Nolis"
pubDate: "Mon, 21 Nov 2022 19:49:40 -0000"
authors:
  - Heather Nolis
  - Sam Charrington
difficulties:
  - intermediate
linktypes:
    - podcastepisode
tags:
    - NLP
    - Speech to Text
    - inspiration
    - R
    - Python
---

## Engineering Production NLP Systems at T-Mobile with Heather Nolis
Is a podcast episode of TWIML-AI and can be found in your podcaster by searching for "TWIML" or by adding [this RSS feed](https://feeds.megaphone.fm/MLN2155636147?post_type=episodes) or going to <https://twimlai.com/podcast/twimlai/engineering-production-nlp-systems-at-t-mobile-with-heather-nolis/>.

In this episode (600) Sam Charrington interviews [Heather Nolis](https://www.linkedin.com/in/heathernolis) senior principle engineer at T-mobile. Heather works on tools that help customer service people with their work. 

> Today weâ€™re joined by Heather Nolis, a principal machine learning engineer at T-Mobile. In our conversation with Heather, we explored her machine learning journey at T-Mobile, including their initial proof of concept project, which held the goal of putting their first real-time deep learning model into production. We discuss the use case, which aimed to build a model customer intent model that would pull relevant information about a customer during conversations with customer support. This process has now become widely known as blank assist. We also discuss the decision to use supervised learning to solve this problem and the challenges they faced when developing a taxonomy. Finally, we explore the idea of using small models vs uber-large models, the hardware being used to stand up their infrastructure, and how Heather thinks about the age-old question of build vs buy. 


## what do I think about it
Wide ranging look into how you to do real time NLP in production settings.
Listen to this episode for inspiration on how to really create products for humans. 
Heather recommends combining small models in stead of training one large model that does everything for speed of development. 
She created her own taxonomy of intents for custumers. 
